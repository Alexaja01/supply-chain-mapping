# Supply Chain Mapping System

**Agent-Driven US Refined Products Supply Chain Mapping**

[![Status](https://img.shields.io/badge/status-active%20development-blue)]()
[![Python](https://img.shields.io/badge/python-3.x-blue)]()
[![License](https://img.shields.io/badge/license-private-red)]()

---

## ğŸ¯ Overview

An intelligent, **AI-powered system** that automatically maps the entire US refined products supply chain from refinery tailgate through pipelines, rail, and marine transport to terminal racks. Built using Claude AI agents to automate data collection and maintenance.

### What It Does

- ğŸ” **Discovers** terminals with IRS Terminal Control Numbers (TCNs)
- ğŸ—ºï¸ **Maps** pipeline connections from refineries to terminals
- ğŸ“Š **Tracks** transportation tariffs (pipeline, rail, marine)
- ğŸ”— **Links** the entire supply chain end-to-end
- âœ… **Validates** data quality automatically
- âš¡ **Updates** continuously with minimal human oversight

### Why It Matters

**Traditional Approach:**
- ğŸ“ Manual data collection: 65 hours/week
- ğŸ’° Cost: $80-120K/year for analyst
- ğŸ“‰ Limited scalability: ~50-100 terminals max
- âš ï¸ High error rate, data staleness

**This System:**
- ğŸ¤– Automated collection: 80-90% autonomous
- ğŸ’µ Cost: $4-6K/year in AI API
- ğŸ“ˆ Highly scalable: 500+ terminals
- âœ¨ High quality, always current

**Savings: $70-110K per year**

---

## âœ¨ Key Features

### ğŸ¤– Autonomous Agents
- **Terminal Discovery Agent** - Finds terminals from IRS publications
- **Pipeline Tariff Agent** - Extracts FERC tariffs automatically
- **Rail Rate Agent** - Tracks Class I railroad rates
- **Quality Assurance Agent** - Validates data continuously
- *(10 agent types planned)*

### ğŸ“Š Comprehensive Data Model
- 15 database tables covering terminals, pipelines, refineries
- Historical tracking with start/end dates
- Ownership change monitoring
- Complete costing data (tariffs, rates, charges)

### ğŸ›ï¸ Task Orchestration
- Scheduled daily, weekly, monthly updates
- Priority-based task queue
- Human review workflow for exceptions
- Performance monitoring and metrics

### ğŸ“š Built-In Intelligence
- Confidence scoring on all data
- Automatic quality validation
- Anomaly detection
- Human review flagging (only 10-20% of items)

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.x** - [Download](https://www.python.org/downloads/)
- **Anthropic API Key** - [Get one](https://console.anthropic.com/)
- **Windows 10/11** or **macOS** or **Linux**

### Installation

1. **Clone or download** this repository

2. **Install dependencies:**
   ```bash
   pip install anthropic
   ```

3. **Create the database:**
   ```bash
   python create_database.py
   ```

4. **Test the setup:**
   ```bash
   python getting_started_simple.py YOUR_API_KEY
   ```

That's it! You're ready to go. ğŸ‰

---

## ğŸ“– Usage

### Easy Way (Double-Click Scripts)

**Windows:**
1. Edit `run_daily_update.bat` - add your API key on line 22
2. Double-click the file to run

**Mac/Linux:**
1. Edit `run_daily_update.sh` - add your API key on line 13
2. Double-click to run (or `./run_daily_update.sh`)

See [EASY_DOUBLE_CLICK_GUIDE.md](EASY_DOUBLE_CLICK_GUIDE.md) for details.

### Command Line

```bash
# Check system status
python orchestrator.py --api-key YOUR_KEY status

# Run daily updates
python orchestrator.py --api-key YOUR_KEY daily

# Run weekly updates
python orchestrator.py --api-key YOUR_KEY weekly

# View items needing review
python orchestrator.py --api-key YOUR_KEY review

# Run specific agent
python terminal_discovery_agent.py YOUR_API_KEY
```

### First Data Collection

**Option A: Import Existing Excel Data** (Recommended - fast!)
```bash
# Build and run the Excel import agent
python excel_import_agent.py YOUR_API_KEY
# Loads 200+ terminals from your existing work
```

**Option B: Discover Terminals from IRS**
```bash
# Run terminal discovery
python terminal_discovery_agent.py YOUR_API_KEY
# Finds terminals from IRS Publication 510
```

---

## ğŸ“ Project Structure

```
supply-chain-mapping/
â”œâ”€â”€ ğŸ Python Files
â”‚   â”œâ”€â”€ config.py                      # Configuration & paths
â”‚   â”œâ”€â”€ orchestrator.py                # Main coordinator
â”‚   â”œâ”€â”€ create_database.py             # Database setup
â”‚   â”œâ”€â”€ terminal_discovery_agent.py    # First agent (working)
â”‚   â””â”€â”€ supply_chain.db                # SQLite database
â”‚
â”œâ”€â”€ ğŸ“œ Scripts
â”‚   â”œâ”€â”€ run_daily_update.bat           # Windows automation
â”‚   â”œâ”€â”€ run_daily_update.sh            # Mac/Linux automation
â”‚   â””â”€â”€ getting_started_simple.py      # Quick test
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                      # This file
â”‚   â”œâ”€â”€ PROJECT_STATE.md               # Current status (update often!)
â”‚   â”œâ”€â”€ DEVELOPMENT_GUIDE.md           # Technical how-to
â”‚   â”œâ”€â”€ BEGINNERS_GUIDE.md             # Non-technical guide
â”‚   â””â”€â”€ agent_driven_framework.md      # Architecture (100+ pages)
â”‚
â””â”€â”€ ğŸ“‚ Reference
    â”œâ”€â”€ excel/
    â”‚   â””â”€â”€ Costing_Data_Final.xlsx    # Existing data (200+ terminals)
    â””â”€â”€ sample_tariffs/
        â””â”€â”€ (sample PDFs)              # For agent training
```

**External (not in Git):**
```
C:\Users\[you]\supply-chain\tariff_library/
â””â”€â”€ (100+ tariff PDFs)                 # Full collection
```

---

## ğŸ—„ï¸ Database

### Schema

**15 Tables:**
- `terminals` - Terminal master data with TCNs
- `pipelines` - Pipeline infrastructure
- `rail_connections` - Rail connections
- `marine_facilities` - Docks and ports
- `refineries` - Refinery information
- `terminal_pipeline_links` - Connections
- `pipeline_refinery_links` - Connections
- `pipeline_tariffs` - FERC tariffs
- `terminal_rates` - Terminal charges
- `rail_rates` - Railroad rates
- `agent_tasks` - Task queue
- `data_quality_log` - Quality tracking
- `agent_metrics` - Performance metrics
- `ownership_changes` - M&A history
- `source_documents` - Document tracking

**3 Views:**
- `v_active_terminals` - Current terminals
- `v_active_pipeline_tariffs` - Current tariffs
- `v_review_queue` - Items needing human review

### Example Queries

```sql
-- View all active terminals
SELECT * FROM v_active_terminals;

-- Count terminals by state
SELECT state, COUNT(*) as count
FROM terminals
GROUP BY state
ORDER BY count DESC;

-- View items needing review
SELECT * FROM v_review_queue;

-- Check agent performance
SELECT agent_type, COUNT(*) as tasks_completed
FROM agent_tasks
WHERE status = 'Completed'
GROUP BY agent_type;
```

---

## ğŸ¤– Agents

### Currently Built

| Agent | Status | Description |
|-------|--------|-------------|
| Terminal Discovery | âœ… Working | Finds terminals from IRS Pub 510 |
| Orchestrator | âœ… Working | Coordinates all agent tasks |

### Planned

| Agent | Priority | Description |
|-------|----------|-------------|
| Excel Import | ğŸ”¥ High | Import existing 200+ terminals |
| Pipeline Tariff | ğŸ”¥ High | Extract FERC tariffs |
| Rail Rate | âš¡ Medium | Collect railroad rates |
| Terminal Info | âš¡ Medium | Scrape operational details |
| Refinery Linkage | âš¡ Medium | Map refinery connections |
| Ownership Tracking | âš¡ Medium | Monitor M&A activity |
| Data Normalization | ğŸ“Š Low | Standardize formats |
| Quality Assurance | ğŸ“Š Low | Validate data quality |
| Linkage Validation | ğŸ“Š Low | Verify supply chain paths |

---

## âš™ï¸ Configuration

All settings are in **`config.py`**:

```python
import config

# Use in your code
db_path = config.DATABASE_PATH
tariff_path = config.PIPELINE_TARIFFS
model = config.CLAUDE_MODEL
```

**Key Settings:**
- Database location
- Tariff library paths
- API model and tokens
- Quality thresholds
- Task priorities

**To change paths:** Edit config.py once, all files update automatically

---

## ğŸ“Š Success Metrics

### Current Status
- **Terminals:** 0 (ready to populate)
- **Automation Rate:** N/A (not yet running)
- **Data Quality:** N/A (no data yet)

### Targets

**Phase 1 (Month 1):**
- ğŸ¯ Automation: 70%+
- ğŸ¯ Quality: 90%+
- ğŸ¯ Coverage: 50+ terminals
- ğŸ¯ Human time: <20 hrs/week

**Phase 2 (Months 2-3):**
- ğŸ¯ Automation: 80%+
- ğŸ¯ Quality: 95%+
- ğŸ¯ Coverage: 200+ terminals
- ğŸ¯ Human time: <15 hrs/week

**Phase 3 (Months 4-6):**
- ğŸ¯ Automation: 85-90%
- ğŸ¯ Quality: 95%+
- ğŸ¯ Coverage: 400+ terminals
- ğŸ¯ Human time: <15 hrs/week

---

## ğŸ’° Cost Analysis

### System Costs
- **Setup:** $50-100 (one-time, API testing)
- **Operation:** $300-500/month
- **Annual:** ~$4,000-6,000

### Cost Breakdown
- Daily workflows: ~$10-15/month
- Weekly workflows: ~$6-12/month
- Monthly workflows: ~$10-20/month
- Human review: Variable

### Comparison

| Approach | Annual Cost | Effort | Scalability |
|----------|-------------|--------|-------------|
| Manual (1 FTE) | $80-120K | 65 hrs/week | 50-100 terminals |
| Data subscription | $50-200K | Varies | Limited |
| **This System** | **$4-6K** | **10-15 hrs/week** | **500+ terminals** |

**ROI: $70-110K/year savings minimum**

---

## ğŸ“š Documentation

### For Everyone
- **README.md** (this file) - Overview and quick start
- **BEGINNERS_GUIDE.md** - Step-by-step for non-technical users
- **EASY_DOUBLE_CLICK_GUIDE.md** - Simplest way to use
- **QUICK_START_CHEATSHEET.txt** - One-page reference

### For Developers
- **DEVELOPMENT_GUIDE.md** - Technical how-to with code examples
- **agent_driven_framework.md** - Complete architecture (100+ pages)
- **PROJECT_STATE.md** - Current status (update frequently!)

### For Future You
- **HOW_TO_PRESERVE_AND_ITERATE.md** - Long-term maintenance
- **NEW_SESSION_TEMPLATE.md** - Starting new Claude sessions

**ğŸ“Œ Keep PROJECT_STATE.md updated - it's your project's memory!**

---

## ğŸ”„ Typical Workflows

### Daily Routine (2-3 minutes)
```bash
# Option 1: Double-click
run_daily_update.bat  # (Windows)

# Option 2: Command line
python orchestrator.py --api-key YOUR_KEY daily
```

**What it does:**
- Checks for new FERC tariff filings
- Monitors ownership change announcements
- Runs quality checks on random sample
- Flags items for review if needed

### Weekly Review (1-2 hours)
1. Run weekly update
2. Check review queue
3. Validate flagged items
4. Approve or correct data
5. Update PROJECT_STATE.md

### Monthly Audit (2-3 hours)
1. Run monthly update
2. Review performance metrics
3. Check coverage gaps
4. Plan new data sources
5. Refine quality thresholds

---

## ğŸ› ï¸ Development

### Adding a New Agent

1. **Copy the template** from DEVELOPMENT_GUIDE.md
2. **Or copy** terminal_discovery_agent.py
3. **Customize** for your specific task
4. **Test** with sample data
5. **Integrate** with orchestrator
6. **Document** in PROJECT_STATE.md

See [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md) for complete instructions.

### Making Changes

1. **Edit files** locally
2. **Test** your changes
3. **Open GitHub Desktop**
4. **Commit** with descriptive message
5. **Push** to GitHub

### Getting Help

**For technical issues:**
- Check DEVELOPMENT_GUIDE.md troubleshooting
- Review agent_driven_framework.md
- Search error message online

**For Claude assistance:**
1. Start new Claude session
2. Upload PROJECT_STATE.md + DEVELOPMENT_GUIDE.md
3. Describe what you want to accomplish
4. Claude can continue building with full context

---

## ğŸ” Security

### API Keys
- âš ï¸ **NEVER commit API keys to GitHub**
- âœ… Pass as command-line arguments
- âœ… Or use environment variables
- âœ… Keep in password manager

### Data
- ğŸ”’ Repository is **private**
- ğŸ”’ Sensitive data not committed
- ğŸ”’ Tariff library stays local
- ğŸ”’ Regular backups recommended

### Backups

**Automated (GitHub):**
- All code
- Documentation
- Sample references

**Manual (Recommended):**
- `supply_chain.db` - Weekly to external drive
- `tariff_library/` - Monthly backup
- Configuration files

---

## ğŸ› Troubleshooting

### Common Issues

**"Python is not recognized"**
```bash
# Reinstall Python, check "Add Python to PATH"
```

**"No module named 'anthropic'"**
```bash
pip install anthropic
```

**"Database is locked"**
```python
# Close other connections
conn.close()
```

**"Can't find config module"**
```bash
# Make sure you're in the right directory
cd C:\Users\[you]\supply-chain\supply-chain-mapping
```

See [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md) for complete troubleshooting guide.

---

## ğŸ—ºï¸ Roadmap

### âœ… Phase 1: Foundation (Week 1-4) - IN PROGRESS
- [x] Database schema
- [x] Orchestrator system
- [x] Terminal Discovery Agent
- [x] Documentation suite
- [x] GitHub repository
- [ ] First data collection
- [ ] Quality validation

### â³ Phase 2: Expansion (Week 5-12)
- [ ] Excel Import Agent
- [ ] Pipeline Tariff Agent
- [ ] Rail Rate Agent
- [ ] 100+ terminals mapped
- [ ] Automated scheduling
- [ ] Review dashboard

### ğŸ”® Phase 3: Production (Week 13-24)
- [ ] All 10 agent types
- [ ] 400+ terminals
- [ ] Complete network mapping
- [ ] Advanced analytics
- [ ] Performance optimization

---

## ğŸ“ Support

### Resources
- **Documentation:** See files listed above
- **Issues:** Use GitHub Issues (if enabled)
- **Questions:** See NEW_SESSION_TEMPLATE.md for asking Claude

### Contributing

This is a private project, but if you're collaborating:

1. Fork the repository
2. Create your feature branch
3. Test thoroughly
4. Update documentation
5. Submit pull request

---

## ğŸ“„ License

This is a **private project** - All rights reserved.

Not for public distribution.

---

## ğŸ™ Acknowledgments

**Built with:**
- [Claude](https://www.anthropic.com/claude) - AI agent framework
- [Python](https://www.python.org/) - Core language
- [SQLite](https://www.sqlite.org/) - Database
- [GitHub](https://github.com/) - Version control

**Based on:**
- Previous manual costing work (200+ terminals)
- FERC tariff data (public domain)
- IRS Publication 510 (public domain)
- Industry knowledge and expertise

---

## ğŸ“ˆ Project Status

**Last Updated:** February 10, 2026

**Current Phase:** Initial Setup Complete  
**Next Milestone:** First data collection  
**Overall Status:** ğŸŸ¢ Active Development

See [PROJECT_STATE.md](PROJECT_STATE.md) for detailed current status.

---

## ğŸš€ Get Started Now

```bash
# 1. Create database
python create_database.py

# 2. Test setup
python getting_started_simple.py YOUR_API_KEY

# 3. Run first agent
python terminal_discovery_agent.py YOUR_API_KEY

# 4. Check what happened
python orchestrator.py --api-key YOUR_KEY status
```

**Ready to automate your supply chain mapping! ğŸ‰**

---

*For detailed instructions, see [BEGINNERS_GUIDE.md](BEGINNERS_GUIDE.md)*  
*For technical details, see [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md)*  
*For current status, see [PROJECT_STATE.md](PROJECT_STATE.md)*
